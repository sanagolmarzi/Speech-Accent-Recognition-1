به نام خدا 	
ترجمه مقاله َ
Classification of Accents of English Speakers by Native Language
طبقه بندی لهجه های انگلیسی زبانان بر اساس زبان مادری
مترجم : ثنا گلمرزی الاصل 40014140111038 
تهران جنوب 
استاد گرامی : دکتر مهدی اسلامی
مقدمه:
لهجه ها می توانند در موارد خیلی زیادی مانند گذشته و زبان محلی (زبان مادری )محل و منطقه ..... گوینده رو بیان کند تشخیص انواع مختلف لهجه ها می تواند کیفیت سخنرانی را به رو نویسی متن با اجازه دادن به پیش پردازش خاص ظبط بر اساس نوع لهجه بهبود ببخشد . هدف ما طبقه بندی لهجه های مختلف بخصوص لهجه های  خارجی گوینده ها با زبان مادری شونن با توجه به به ضبط یک گوینده یک اسکریپت شناخته شده از کلمات انگلیسی ما می خواهیم زبان مادری گوینده را پیشبینی کنیم.
مجوعه داده ها :
موارد ضبط شده از دانشگاه جورج میسون دانشکده انگلیسی از English Speech  منتشر شده است هر ضبط از یک فرد با همان اسکریپت یا متن انگلیسی است .متن به این شزح است :
Please call Stella. Ask her to bring these things 
with her from the store: Six spoons of fresh snow
peas, five thick slabs of blue cheese, and maybe a 
snack for her brother Bob. We also need a small
plastic snake and a big toy frog for the kids. She
can scoop these things into three red bags, and we
will go meet her Wednesday at the train station.

برای هر فایل ما یک آرشیو حاوی اطلاعاتی درباره پس زمینه  سابقه گوینده مانند :سن, جنس, زادگاه زبان مادری و زبان های دیگری که صحبت می کندد و  نیز مدت زمانی که انگلیسی صحبت می کنند و محل اقامت آن ها . ویژگی که برای ما  پر اهمیت است زبان مادری هر گوینده است .ما تصمیم گرفتیم که تنها لهجه گویندگان مرد را از 5 زبان رایج در آرشیو را تشخیص دهیم انگلیسی, اسپانیایی, عربی, فرانسوی ,وماندارین (ماندارین گروهی از زبان ها و گویش های سینیتی است که به طور بومی در بیشتر شمال و جنوب غربی چین صحبت می شود. این گروه شامل گویش پکن، پایه واج شناسی چینی استاندارد، زبان رسمی چین است.) در مجموع 293 نمونه ضبط شده .




مروری بر روش ها :

مشخصه های متمایز در بین لهجه ها الگوهای مختلف بیان تلفظ خاص هجا به دلیل مشکلات گویندگان است که در زبان مادری خود ظاهر نمیشود .بنابراین ما الگوریتم های برای طبقه بندی براساس این تفاوت با مقایسه هجا ها در هر گوینده در هر ضبط و اسفاده از این اطلاعات به منظور مدل سازی چگونگی بیان هر اسکریپت در هر گوینده است را ارائه می کنیم .و با تست این اطلاعات تا تعیین که  کدام یک از این لهجه ها استفاده می شد  بیشتر شبیه است .الگوریتم طراحی ما از 2 مرحله طراحی شده است . ابتدا ما یک الگوریتم طبقه بندی برای هر هجا ایجاد می کنیم که به ما نشان می دهد که لهجه گوینده بر اساس ان حجا خاص است .  یک لیست از کلمات مهم را انتخاب می کنیم  ان ها رو به عنوان لایک لیست معرفی می کنیم و کلمه های غیر مهم و تکراری را فیلتر می کنیم 

پیش پردازش اطلاعات :

ضبط هایی که برای پردازش گفتار استفاده میشوند، معمولاً قبل از استخراج بردارهای ویژگی، نیاز به پیش پردازش مناسبی دارند. اولین مرحله پیش پردازش حذف نویز پس زمینه بوده است.با این حال،مجموعه داده دارای حداقل نویز پس زمینه بود. بیشتر پیش پردازش های ما شامل تقسیم کردن ضبط همانطور که در بالا ذکر شدبود. از آنجایی که بیشتر کلما ت در متن تک هجا هستند، ضبط رابه کلما ت جداگانه تقسیم می کنیم. ما کلما ت رابا استفاده ازسیستم تقسیم بندی  MAUS تراز کردیم که از انواع فیلتر ها پردازش ها و اکتشافات استفاده می کند تا بتواند تقسیمات بین کلمه را جست وجوکند . ما از MAUS برای جدا کردن فایل های صوتی به فایل های صوتی کوچکتر برای هر کلمه  استفاده کردیم. کلیپ های همان کلمه ای که توسط گویندگان مختلف صحبت می شود ناگزیر به علت تغییرات طبیعی در نرخ صحبت ار فرد به فرد طول می کشد ما این تغییرات را بعدا در مرحله استخراج ویژگی محاسبه می کنیم. 












شکل1 )مربوط به روش MAUS است که صدای جمله ‘six spoons of fresh snow peas ‘ در دامنه زمان و فرکانس نشان داده می شود و مرز ها ی
هجا/کلمه استخراج شده ازبرنامه به رنگ آبی نشان داده شده است.  

گام نهایی شامل عادی سازی کلیپ با حجم و (ولوم)بود زیرا هر گوینده ممکن است ولوم متفاوت و  در فاصله متفاوتی با میکروفون صحبت کند .ما می توانیم برای تغییر حجم پس از هماهنگ کردن کلمات با مقیاس بندی بر اساس افراط و تراز  از هر کلمه به حجم متوسط هر کلمه در کل مجموعه آموزشی نتظیم کنیم .

انتخا ب ویژگی در هر کلمه:

برای هر نمونه از هر کلمه ویژگی های ظرایب طیف فرکانسی (MFCC) که یک روش ساده و جمع و جور برای استخراج ویژگی هایی که نمونه های صوتی شکل موج را نشان می دهند .در مقالات گذشته به خوبی نشان می دهند که MFCC ها برای شناخت گفتار مفید هستند که دقیقا همان چیزی است که ما انجام می دهیم .طیف MELیک روش طبقه بندی فرکانس های یک صدا به نحوه ی است که به طور موثر واج ها را تشخیص می دهد فرایند MFC یک تبدیل فوریه سیگنال را می گیرد .و به عنوان طیف MELتعریف شده قرار  میگیرد .پنجره زمانی باید کوتاه در حدود 10 میلی ثانیه باشد تا این پردازش موثر باشد همان طور که در بالا ذکر شد ما نرخ های گفتار هر کلمه در حین استخراج کلمه با MFCCنرمالایز می کنیم .ما این کار را با مقیاس بندی نرخ نمونه برداری انجام دادیم .با این مقایسه نمونه برداری ها از فایل ها  WARانجام می دهیم که اغلب از میکروفون به میکروفن فرق دارد بردار حاصل از MFCCها برای هر کلمه مجموعه ای از ویژگی های است که ما برای مدل سازی هر کلمه استفاده می کنیم .
از ان جایی که بردار ویژگی دارای ویژگی هایی زیاد تر از انچه ما می خواهیم دارد ما 16 ویژگی مهم برای هر کلمه را به کمک PCAشناسایی می کردیم .
 برای هر کلمه ما فقط یک بردار MFCCاز شاخص های خاص را تعیین می کنیم را شناسایی می کنیم به طور کلی با استفاده از چنین ویژگی های کوتاه مدت برای علمی بودن محاسبات ضروری است .











شکل2) ردیف بالانمونه دامنه فرکانسی و ردیف پایین نمایشی از ضرایب  cepstrum است  قرمز در مربع ها نشان دهنده اعداد با ارزش است ما از این برای ویژگی هامون استفاده می کنیم . 


مدل کلمه:

از انجایی که مجموع داده های ما برچسب گزاری شده بود ما از هر دو الگوریتم یادگیری تحت نظارت شده و بدون نظارت استفاده کردیم تا مدل ها را برای هر کلمه ایجاد می کنیم برای یادگیری تحت نظارت 80% مدل هابه طور تصادفی نمونه برداری شده و چندین زمان برای محاسبه خطای مدل ما ,مدل موجود را برای 20% باقی مانده از مجموعه داده ها نیز اجرا می کنیم و خطا ی متوسط را بدست می اوریم مجموعه شامل 205 نمونه بود و مجموعه ازمون شامل 88 نمونه بود الگوریتم های نظارتی شامل SVM, Naïve Bayes, Softmax logistic regression, and GDA   .  
مدل SVM  همانطور که در کلاس با یک هسته گاوسی اموخته شده اجرا شد .
مدل naive bayes  برای طبقه بندی بین کلاس های چندگانه به جای دوگانه .ما طبقه بندی باینری را بر روی هر دسته انجام دادیم به طوری مه تمام نمونه هایی که در ان دسته عنوان مثبت طبقه بندی می شوند و تمام نمونه های دیگر به عنوان منفی طبقه بندی می شوند .
 مدل  softmax به منطور به حداقل رساندن تابع هزینه و به منظور کاهش هزینه ها به 5 کلاس تقسیم می شود    


















ما همچنین با دو الگوریتم یادگیری بدون نظارت که یک مدل مخلوط گاوسی و خوشه بندی k-means ازمایش کردیم تا سیستم که ایا خوشه ها بابرچسب هایی که با منطق هستند . همچنین از تحقیقات قبلی GMMها به نظر می رسد که استاندارد برای وظایف مانند شناخت و تجزیه تحلیل گفتار  است .
 GMMها به K-meam بدون اصلاح در کلاس اموخته و سپس با برچسب ها مقایسه شدند 

انتخاب کلمه PCA: 
برای از بین بردن تمایل ناشی از تکرار در کلمات یا کلمات بی اهمیت قدرت انالیز هر کلمه نشان دهنده لهجه خاص را نشان می دهیم .ما از مدل SVMبرای  طبقه بندی زبان انگلیسی 4تا از ویژگی ها در هر کلمه استفاده می کنیم و از ویژگی ها 4 تا زبان دیگر  در هر کلمه استفاده می کنیم . کلمه ی که کمترین خطا را در بین زبان های ما دارد را به عنوان ویژگی الگوریتم های طبقه بندی انتخاب می کنیم .
  
شکل 3) خطای نسبی طبقه بندی از مدل های اموزش داده شده بر روی هر کلمه در امتدادمحور افقی کلمه در حال اموزش قرار دارد در امتداد محور عمودی زبان مادری در برابر انگلیسی طبقه بندی میشود .مستطیل روشن تر برای یک کلمه نشان دهنده دقت طبقه بندی بالاتر از سایر  کلمه ها است . 


نتیجه: 
بهترین نرخ طبقه بندی ما برای یادگیری تحت نظارت با GDA وnaive حدودا 42% است .و با GMMوK-MEANS ماتوانستیم به 34% برچسب زدن با دقت متوسط را بدست بیاوریم





شکل 4الف(سمت چپ)میانگین دقت طبقه بندی هر لهجه در تمامی مدل ها تعداد نمونه ها برای هر نوع به ترتیب 56.100.31.24.82
شکل 4ب (سمت راست )میانگین دقت طبقه بندی در هر مدل 

خطاهای اموزش و تست مدل های ما در زیر به طور خلاصه شده امده است

    






نتیجه گیری :
دقت طبقه بندی نهایی ما 40% بهتر از متغیر تصادفی یا شانسی (20%) بود و با سایر تلاش ها برای طبقه بندی لهجه ها همتراز هستند.همانطور که انتظار می رفت الگوریتم های یادگیری تحت نظارت عملکرد بهتری از الگوریتم های یادگیری بدون نظارت داشت(شکل 4) .در میان انواع مختلف یادگیری تحت نظارت و بدون نظارت روش های naïve and GDA موفق ترین مدل این روش ها در حدس زدن لهجه فایل های صوتی بودند .ما بر این باور هستیم که naïve and GDA بهترین نتیجه را دارند زیرا هر دو عامل توزیع نابرابر قبلی نمونه ها در هر دسته لهجه هستند.همچچنین دقت طبقه بندی برای هر زبان یک همبستگی بسیار قوی با تعداد نمونه برای هر زبان دارد هر چند که ما چندین منبع خطا ی خارج از کنترل داشتیم به عنوان مثال ما نیروی انسانی لازم برای تایید دستی نتایج جدا سازی کلمات خود در حین پردازش  MAUS نداشتیم فقط این موارد را در نظر گرفتیم زبان مادری گوینده به جای مدت اشنایی ان با زبان انگلیسی این منابع خطا ها ممکن است باعت معرفی نادرست لهجه ها شوند .
مشکل دوم بیشتر مربوط به گویندگان ماندارین رخ داد (به غیر از حجم نمونه کوچیک )برای طبقه بندی پایین ماندارین است از 2 نمونه ماندارین ها حدود 20مورد  از ان هاسال ها در یک کشور انگلیسی زبان زندگی کرده اند و ما به کل فایل های صوتی 24 نفر گوش دادیم و تعداد  انگشت شماری از انها با لهجه صحبت می کنند تقریبا کامل و بی نقص انگلیسی صحبت می کنند . برای الگوریتم های یادگیری نظارت شده، نتیجه احتمالی این "برچسب گذاری اشتباه" مدلی از لهجه ماندارین است که بسیار شبیه به انگلیسی بدون لهجه است. این امر بر طبقه بندی تمام نمونه های انگلیسی بدون لهجه تأثیر می گذارد (که ما تعداد زیادی از آنها را داریم)، که تقریباً به طور دلخواه می توانند در کلاس "انگلیسی" یا "ماندارین" طبقه بندی شوند. برای یادگیری بدون نظارت الگوریتم‌ها، نتیجه محتمل این خواهد بود که نمونه‌های ماندارین دارای برچسب اشتباه با نمونه‌های انگلیسی بدون لهجه خوشه‌بندی شوند. اگر فقط تعداد انگشت شماری (نمونه های واقعاً برجسته) در خوشه "ماندارین" دسته بندی شوند، دقت طبقه بندی پایین نمونه های ماندارین را توضیح می دهد. 
به طور کلی، ما یک الگوریتم طبقه بندی معقول را به  دست آورده ایم، اما قطعا فضایی برای بهبود در روش شناسی ما وجود دارد.
آینده:
اقدامات بالقوه‌ای وجود دارد که می‌توانیم برای بهبود نتایج خود در آینده، از کیفیت داده‌هایمان شروع کنیم. همانطور که در بالا مورد بحث قرار گرفت، برخی از نمونه‌های ما به این معنا که زبان مادری هر یک از گوینده‌ها خود شناسایی شده بود و گاهی با لهجه گفتاری آن‌ها ارتباطی نداشت، «برچسب اشتباه» داشتند. در آینده، برای ایجاد مدل‌های بهتری از لهجه‌های واقعی، هر سخنران را در نظر می‌گیریم آشنایی با زبان انگلیسی به عنوان تخمینی از سنگینی لهجه آنها، با استفاده از داده های ارائه شده از طول و ماهیت مواجهه آنها با انگلیسی. برای مراحل پیش پردازش داده ها و طراحی کلی مدل، چندین پیشرفت وجود دارد که می توان مدل ما را دقیق تر کرد. اول، ما یک سیستم مناسب (MAUS) برای تقسیم کردن ضبط‌ها به کلمات در اختیار داشتیم، اما به جای تکیه بر این واقعیت که بیشتر کلمات متن تک هجا، در حالت ایده‌آل می‌توانیم یک مدل قوی‌تر بسازیم و ضبط‌هایمان را به هجاها یا حتی بیشتر به واج‌های جداگانه تقسیم کنیم. در مرحله بعد، الگوریتم‌های طبقه‌بندی هر کلمه فقط 5-1سخت را به نمایش می‌گذارند تا نشان دهند کدام یک از پنج نوع لهجه برای آن کلمه محتمل‌تر است. مشکل این رویکرد این است که به سادگی لهجه را با بالاترین احتمال پسین می گیرد و احتمالات پسین همه لهجه ها را بدون توجه به مقادیر آنها کنار می گذارد. با توجه به آنچه می دانیم، یک کلیپ فقط کمی بهتر می تواند با لهجه ماندارین مطابقت داشته باشد .بیش از آن که با لهجه انگلیسی مطابقت داشته باشد (که به راحتی ممکن است زمانی اتفاق بیفتد که نمونه‌های ماندارین با برچسب غلط ما باعث می‌شوند مدل‌های انگلیسی و ماندارین بسیار شبیه باشند). یک راه حل این است که الگوریتم های طبقه بندی برای هر کلمه بردار هر پنج احتمال پسین را به دست آورند. مرحله دوم مدل ما باید کمی اصلاح شود تا احتمالات خلفی پنج لهجه در تمام هجاها را در نظر بگیرد. در نهایت، مرحله دوم مدل ما برچسب‌های سیاه و سفید را به هر کلمه در مورد اهمیت یا عدم تمایز بین لهجه‌ها اختصاص می‌دهد. به جای اختصاص دادن این برچسب‌های سیاه و سفید، می‌توانیم از نوعی رگرسیون خطی وزن‌دار برای وزن دادن هجاها استفاده کنیم. و به دلیل تلفظ خاصی ا ز هجاهای خاص یک پرچم قرمز برای لهجه های خاص هستند، حتی ممکن است هجاها را برای هر نوع لهجه متفاوت وزن کنیم، با استفاده از لهجه هایی که در بالا توضیح داده شد، هجاهای آخر را محاسبه کنیم و بالاترین لهجه را محتمل ترین لهجه در نظر بگیریم. با توجه به اینکه عامل تمایز بین لهجه ها تلفظ تک تک هجاها و واج ها است، این سه پیشرفت باید مدل ما را بیشتردقیق کند چون تاکید بیشتری روی ان است . مسیر جالب و مرتبطی که می‌توانیم دنبال کنیم، وجود لهجه‌های مختلف انگلیسی و لهجه‌های منطقه‌ای است، مانند لهجه‌های بریتانیایی یا لهجه‌های منطقه‌ای ایالات متحده مانند لهجه‌های بوستونی. با توجه به نمونه‌های کافی، امیدواریم بتوانیم نمونه‌های انگلیسی خود را در لهجه‌های منطقه‌ای مختلف دسته‌بندی کنیم و مدل‌هایی را برای این لهجه‌های منطقه‌ای به همان روشی که مدل‌هایی برای لهجه‌های خارجی ایجاد کردیم، ایجاد کنیم. این مدل‌ها می‌توانند یک الگوریتم طبقه‌بندی را برای پیش‌بینی اینکه گوینده از کجا سرچشمه می‌گیرد، بر اساس ضبط آنها از اسکریپت تشکیل دهند.





منابع:
1.	[1] "Accent Classification," Phumchanit
Watanaprakornkul, Chanat Eksombatchai, Peter
Chien.
[2] "Accent Issues in Large Vocabulary
Continuous Speech Recognition (LVCSR)," Eric
Chang, Chao Huang, and Tao Chen. Microsoft
Research. August 2011.
[3] "Accent Recognition with Neural Network,"
Matthew Seal, Matthew Murray, Ziyad Khaleq.
[4] "Accurate Short-Term Analysis Of The
Fundamental Frequency And The Harmonics-ToNoise Ratio Of A Sampled Sound." Paul Boersma.
Institute of Phonetic Sciences, University of
Amsterdam. 1993.
[5] "Foreign Accent Classification," Paul Chen,
Julia Lee, Julia Neidert.
[6] "melfcc.m," PLP and RASTA (and MFCC, and
inversion) in Matlab. Daniel P. W. Ellis.
December 2014. Online web resource. 2005.
<http://www.ee.columbia.edu/~dpwe/resource
s/matlab/rastamat/>
[7] "The Munich Automatic Segmentation
System." Ludwig-Maximilians-Universitat,
Munich, Germany. Florian Schiel. December
2014. Web. 21 March 2013.
<http://www.bas.unimuenchen.de/Bas/BasMAUS.html>
[8] "Phonemic Segmentation and Labelling using
the MAUS Technique," Florian Schiel, Christoph
Draxler, Jonathan Harrington. Bavarian Archive
for Speech Signals, Institute for Phonetics and
Speech Processing. Ludwig-MaximiliansUniversitat, Munchen, Germany.
[9] "Praat: doing phonetics by computer." Paul
Boersma, David Weenick. December 2014.
Computer program. University of Amsterdam. 13
November 2014. <http://www.praat.org/>
[10] "The Speech Accent Archive." George Mason
University. Steven H. Weinberger. December
2014. Web. 20 November 2014.
<http://accent.gmu.edu/>
